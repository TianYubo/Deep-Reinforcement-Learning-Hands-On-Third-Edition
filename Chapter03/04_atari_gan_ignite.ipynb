{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 使用PyTorch Ignite训练GAN生成Atari游戏画面\n",
                "\n",
                "本notebook实现了一个生成对抗网络(GAN)，使用PyTorch Ignite框架来训练和生成类似Atari游戏的图像。我们将使用Gymnasium库中的几个Atari游戏环境作为训练数据。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 导入必要的库"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/root/miniconda3/envs/RL/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
                        "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
                    ]
                }
            ],
            "source": [
                "import random\n",
                "import cv2\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from ignite.engine import Engine, Events\n",
                "from ignite.handlers import Timer\n",
                "from ignite.metrics import RunningAverage\n",
                "from ignite.contrib.handlers import tensorboard_logger as tb_logger\n",
                "\n",
                "import torchvision.utils as vutils\n",
                "import gymnasium as gym\n",
                "from gymnasium import spaces\n",
                "\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "log = gym.logger\n",
                "log.set_level(gym.logger.INFO)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 设置超参数\n",
                "\n",
                "定义模型训练和生成过程中需要的各种参数。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "LATENT_VECTOR_SIZE = 100  # 潜在向量的大小\n",
                "DISCR_FILTERS = 64        # 判别器中的基础卷积滤波器数量\n",
                "GENER_FILTERS = 64        # 生成器中的基础卷积滤波器数量\n",
                "BATCH_SIZE = 16           # 批次大小\n",
                "\n",
                "# 输入图像将被缩放的尺寸\n",
                "IMAGE_SIZE = 64\n",
                "\n",
                "LEARNING_RATE = 0.0001    # 学习率\n",
                "REPORT_EVERY_ITER = 100   # 每多少次迭代报告一次训练状态\n",
                "SAVE_IMAGE_EVERY_ITER = 1000  # 每多少次迭代保存一次生成的图像"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 输入预处理包装器\n",
                "\n",
                "创建一个Gymnasium环境包装器，用于预处理输入图像：\n",
                "1. 将图像调整为预定义的大小\n",
                "2. 将颜色通道轴移到第一位置(从HWC格式转为CHW格式)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class InputWrapper(gym.ObservationWrapper):\n",
                "    \"\"\"\n",
                "    输入numpy数组的预处理：\n",
                "    1. 将图像调整为预定义的大小\n",
                "    2. 将颜色通道轴移到第一位置\n",
                "    \"\"\"\n",
                "    def __init__(self, *args):\n",
                "        super(InputWrapper, self).__init__(*args)\n",
                "        old_space = self.observation_space\n",
                "        assert isinstance(old_space, spaces.Box)\n",
                "        self.observation_space = gym.spaces.Box(self.observation(old_space.low), self.observation(old_space.high),\n",
                "                                                dtype=np.float32)\n",
                "\n",
                "    def observation(self, observation):\n",
                "        # 调整图像大小\n",
                "        new_obs = cv2.resize(observation, (IMAGE_SIZE, IMAGE_SIZE))\n",
                "        # 转换 (w, h, c) -> (c, w, h)\n",
                "        new_obs = np.moveaxis(new_obs, 2, 0)\n",
                "        return new_obs.astype(np.float32)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 判别器模型\n",
                "\n",
                "判别器网络接收一个图像作为输入，并输出一个表示该图像是真实的(接近1)还是生成的(接近0)的概率值。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Discriminator(nn.Module):\n",
                "    def __init__(self, input_shape):\n",
                "        super(Discriminator, self).__init__()\n",
                "        # 这个管道将图像转换为单个数字\n",
                "        self.conv_pipe = nn.Sequential(\n",
                "            nn.Conv2d(in_channels=input_shape[0], out_channels=DISCR_FILTERS,\n",
                "                      kernel_size=4, stride=2, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(in_channels=DISCR_FILTERS, out_channels=DISCR_FILTERS*2,\n",
                "                      kernel_size=4, stride=2, padding=1),\n",
                "            nn.BatchNorm2d(DISCR_FILTERS*2),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(in_channels=DISCR_FILTERS * 2, out_channels=DISCR_FILTERS * 4,\n",
                "                      kernel_size=4, stride=2, padding=1),\n",
                "            nn.BatchNorm2d(DISCR_FILTERS * 4),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(in_channels=DISCR_FILTERS * 4, out_channels=DISCR_FILTERS * 8,\n",
                "                      kernel_size=4, stride=2, padding=1),\n",
                "            nn.BatchNorm2d(DISCR_FILTERS * 8),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(in_channels=DISCR_FILTERS * 8, out_channels=1,\n",
                "                      kernel_size=4, stride=1, padding=0),\n",
                "            nn.Sigmoid()\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        conv_out = self.conv_pipe(x)\n",
                "        return conv_out.view(-1, 1).squeeze(dim=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 生成器模型\n",
                "\n",
                "生成器网络接收一个随机潜在向量作为输入，并生成一个与训练数据相似的图像。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Generator(nn.Module):\n",
                "    def __init__(self, output_shape):\n",
                "        super(Generator, self).__init__()\n",
                "        # 管道将输入向量反卷积成 (3, 64, 64) 图像\n",
                "        self.pipe = nn.Sequential(\n",
                "            nn.ConvTranspose2d(in_channels=LATENT_VECTOR_SIZE, out_channels=GENER_FILTERS * 8,\n",
                "                               kernel_size=4, stride=1, padding=0),\n",
                "            nn.BatchNorm2d(GENER_FILTERS * 8),\n",
                "            nn.ReLU(),\n",
                "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 8, out_channels=GENER_FILTERS * 4,\n",
                "                               kernel_size=4, stride=2, padding=1),\n",
                "            nn.BatchNorm2d(GENER_FILTERS * 4),\n",
                "            nn.ReLU(),\n",
                "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 4, out_channels=GENER_FILTERS * 2,\n",
                "                               kernel_size=4, stride=2, padding=1),\n",
                "            nn.BatchNorm2d(GENER_FILTERS * 2),\n",
                "            nn.ReLU(),\n",
                "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 2, out_channels=GENER_FILTERS,\n",
                "                               kernel_size=4, stride=2, padding=1),\n",
                "            nn.BatchNorm2d(GENER_FILTERS),\n",
                "            nn.ReLU(),\n",
                "            nn.ConvTranspose2d(in_channels=GENER_FILTERS, out_channels=output_shape[0],\n",
                "                               kernel_size=4, stride=2, padding=1),\n",
                "            nn.Tanh()\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.pipe(x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 批次迭代器\n",
                "\n",
                "创建一个函数，从Atari游戏环境中收集观察数据，并将它们组织成批次。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def iterate_batches(envs, batch_size=BATCH_SIZE):\n",
                "    batch = [e.reset()[0] for e in envs]\n",
                "    env_gen = iter(lambda: random.choice(envs), None)\n",
                "\n",
                "    while True:\n",
                "        e = next(env_gen)\n",
                "        obs, reward, is_done, is_trunc, _ = e.step(e.action_space.sample())\n",
                "        if np.mean(obs) > 0.01:  # 过滤掉全黑的图像\n",
                "            batch.append(obs)\n",
                "        if len(batch) == batch_size:\n",
                "            # 将输入归一化到[-1..1]并转换为张量\n",
                "            batch_np = np.array(batch, dtype=np.float32)\n",
                "            yield torch.tensor(batch_np * 2.0 / 255.0 - 1.0)\n",
                "            batch.clear()\n",
                "        if is_done or is_trunc:\n",
                "            e.reset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 设置环境和模型\n",
                "\n",
                "初始化游戏环境、模型和优化器。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 设置设备（CPU或GPU）\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"使用设备: {device}\")\n",
                "\n",
                "# 创建游戏环境\n",
                "envs = [InputWrapper(gym.make(name)) for name in ('Breakout-v4', 'AirRaid-v4', 'Pong-v4')]\n",
                "input_shape = envs[0].observation_space.shape\n",
                "print(f\"观察空间形状: {input_shape}\")\n",
                "\n",
                "# 初始化判别器和生成器\n",
                "net_discr = Discriminator(input_shape=input_shape).to(device)\n",
                "net_gener = Generator(output_shape=input_shape).to(device)\n",
                "\n",
                "# 设置损失函数和优化器\n",
                "objective = nn.BCELoss()\n",
                "gen_optimizer = optim.Adam(params=net_gener.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
                "dis_optimizer = optim.Adam(params=net_discr.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
                "\n",
                "# 准备标签\n",
                "true_labels_v = torch.ones(BATCH_SIZE, device=device)\n",
                "fake_labels_v = torch.zeros(BATCH_SIZE, device=device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 定义训练过程\n",
                "\n",
                "使用PyTorch Ignite框架定义训练过程，包括批处理函数和事件处理程序。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_batch(trainer, batch):\n",
                "    \"\"\"\n",
                "    处理一个批次的数据，训练判别器和生成器\n",
                "    \"\"\"\n",
                "    # 生成随机潜在向量\n",
                "    gen_input_v = torch.FloatTensor(BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1)\n",
                "    gen_input_v.normal_(0, 1)  # 用正态分布初始化\n",
                "    gen_input_v = gen_input_v.to(device)\n",
                "    batch_v = batch.to(device)\n",
                "    gen_output_v = net_gener(gen_input_v)\n",
                "\n",
                "    # 训练判别器\n",
                "    dis_optimizer.zero_grad()\n",
                "    dis_output_true_v = net_discr(batch_v)\n",
                "    dis_output_fake_v = net_discr(gen_output_v.detach())\n",
                "    dis_loss = objective(dis_output_true_v, true_labels_v) + \\\n",
                "               objective(dis_output_fake_v, fake_labels_v)\n",
                "    dis_loss.backward()\n",
                "    dis_optimizer.step()\n",
                "\n",
                "    # 训练生成器\n",
                "    gen_optimizer.zero_grad()\n",
                "    dis_output_v = net_discr(gen_output_v)\n",
                "    gen_loss = objective(dis_output_v, true_labels_v)\n",
                "    gen_loss.backward()\n",
                "    gen_optimizer.step()\n",
                "\n",
                "    # 定期保存生成的图像\n",
                "    if trainer.state.iteration % SAVE_IMAGE_EVERY_ITER == 0:\n",
                "        fake_img = vutils.make_grid(gen_output_v.data[:64], normalize=True)\n",
                "        trainer.tb.writer.add_image(\"fake\", fake_img, trainer.state.iteration)\n",
                "        real_img = vutils.make_grid(batch_v.data[:64], normalize=True)\n",
                "        trainer.tb.writer.add_image(\"real\", real_img, trainer.state.iteration)\n",
                "        trainer.tb.writer.flush()\n",
                "        \n",
                "        # 显示生成的和真实的图像\n",
                "        plt.figure(figsize=(10, 5))\n",
                "        plt.subplot(1, 2, 1)\n",
                "        plt.title(\"生成的图像\")\n",
                "        plt.imshow(np.transpose(fake_img.cpu().numpy(), (1, 2, 0)))\n",
                "        plt.axis('off')\n",
                "        \n",
                "        plt.subplot(1, 2, 2)\n",
                "        plt.title(\"真实的图像\")\n",
                "        plt.imshow(np.transpose(real_img.cpu().numpy(), (1, 2, 0)))\n",
                "        plt.axis('off')\n",
                "        plt.show()\n",
                "    \n",
                "    return dis_loss.item(), gen_loss.item()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 设置Ignite引擎和TensorBoard记录器\n",
                "\n",
                "配置PyTorch Ignite引擎，添加指标和处理程序。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 创建Ignite引擎\n",
                "engine = Engine(process_batch)\n",
                "\n",
                "# 设置TensorBoard记录器\n",
                "tb = tb_logger.TensorboardLogger(log_dir=\"runs/atari_gan\")\n",
                "engine.tb = tb\n",
                "\n",
                "# 添加运行平均指标\n",
                "RunningAverage(output_transform=lambda out: out[1]).attach(engine, \"avg_loss_gen\")\n",
                "RunningAverage(output_transform=lambda out: out[0]).attach(engine, \"avg_loss_dis\")\n",
                "\n",
                "# 将指标添加到TensorBoard\n",
                "handler = tb_logger.OutputHandler(tag=\"train\", metric_names=['avg_loss_gen', 'avg_loss_dis'])\n",
                "tb.attach(engine, log_handler=handler, event_name=Events.ITERATION_COMPLETED)\n",
                "\n",
                "# 添加计时器\n",
                "timer = Timer()\n",
                "timer.attach(engine)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 添加日志记录事件处理程序\n",
                "\n",
                "添加事件处理程序，定期记录训练进度和损失值。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@engine.on(Events.ITERATION_COMPLETED)\n",
                "def log_losses(trainer):\n",
                "    \"\"\"记录损失值和训练进度\"\"\"\n",
                "    if trainer.state.iteration % REPORT_EVERY_ITER == 0:\n",
                "        log.info(\"%d 在 %.2f秒内完成: 生成器损失=%f, 判别器损失=%f\",\n",
                "                 trainer.state.iteration, timer.value(),\n",
                "                 trainer.state.metrics['avg_loss_gen'],\n",
                "                 trainer.state.metrics['avg_loss_dis'])\n",
                "        timer.reset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 添加早期停止和模型保存处理程序\n",
                "\n",
                "设置处理程序，在训练过程中定期保存模型，并在达到最大迭代次数时停止训练。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ignite.handlers import ModelCheckpoint, TerminateOnNan\n",
                "\n",
                "# 添加模型保存处理程序\n",
                "checkpoint_handler = ModelCheckpoint('checkpoints', 'gan', n_saved=3, require_empty=False)\n",
                "engine.add_event_handler(Events.ITERATION_COMPLETED(every=5000), checkpoint_handler, {\n",
                "    'generator': net_gener,\n",
                "    'discriminator': net_discr\n",
                "})\n",
                "\n",
                "# 添加NaN检测处理程序\n",
                "engine.add_event_handler(Events.ITERATION_COMPLETED, TerminateOnNan())\n",
                "\n",
                "# 设置最大迭代次数\n",
                "max_iterations = 50000\n",
                "\n",
                "@engine.on(Events.ITERATION_COMPLETED)\n",
                "def stop_training(engine):\n",
                "    \"\"\"在达到最大迭代次数时停止训练\"\"\"\n",
                "    if engine.state.iteration >= max_iterations:\n",
                "        engine.terminate()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 运行训练过程\n",
                "\n",
                "启动训练引擎，开始训练GAN模型。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 运行训练引擎\n",
                "try:\n",
                "    engine.run(data=iterate_batches(envs), max_epochs=1)\n",
                "except KeyboardInterrupt:\n",
                "    print(\"训练被用户中断\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 生成最终样本\n",
                "\n",
                "使用训练好的生成器生成一些最终样本并显示。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 生成16个样本\n",
                "gen_input_v = torch.FloatTensor(16, LATENT_VECTOR_SIZE, 1, 1)\n",
                "gen_input_v.normal_(0, 1)\n",
                "gen_input_v = gen_input_v.to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    gen_output_v = net_gener(gen_input_v)\n",
                "\n",
                "# 显示生成的图像\n",
                "plt.figure(figsize=(10, 10))\n",
                "plt.title(\"生成的Atari游戏画面\")\n",
                "img = vutils.make_grid(gen_output_v.data, nrow=4, normalize=True)\n",
                "plt.imshow(np.transpose(img.cpu().numpy(), (1, 2, 0)))\n",
                "plt.axis('off')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 保存最终模型\n",
                "\n",
                "保存训练好的生成器和判别器模型，以便将来使用。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 保存最终模型\n",
                "torch.save(net_gener.state_dict(), \"final_generator.pth\")\n",
                "torch.save(net_discr.state_dict(), \"final_discriminator.pth\")\n",
                "print(\"最终模型已保存\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 清理资源\n",
                "\n",
                "关闭TensorBoard写入器和游戏环境。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 关闭TensorBoard写入器\n",
                "tb.close()\n",
                "\n",
                "# 关闭环境\n",
                "for env in envs:\n",
                "    env.close()\n",
                "\n",
                "print(\"训练完成！\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 总结\n",
                "\n",
                "在本notebook中，我们使用PyTorch Ignite框架实现了一个生成对抗网络(GAN)，用于生成类似Atari游戏的图像。我们使用了以下几个关键组件：\n",
                "\n",
                "1. **判别器网络**：用于区分真实图像和生成的图像\n",
                "2. **生成器网络**：从随机噪声生成类似游戏的图像\n",
                "3. **PyTorch Ignite引擎**：简化训练循环和事件处理\n",
                "4. **TensorBoard记录**：记录训练进度和可视化结果\n",
                "\n",
                "通过这种方式，我们能够生成类似于Breakout、AirRaid和Pong等Atari游戏的图像。"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
